{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wO20RrFvyx5K"
   },
   "source": [
    "# An introduction to Convolutional Neural Networks in 3 Parts\n",
    "![](https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/dogcat.png)\n",
    "In this notebook we will start with 2 different threads:\n",
    "\n",
    "1. An introduction to processing images. In our previous work with images (for example the MNIST data), the images were provided to us preprocessed. So we got a nicely formated CSV file. In this thread we will learn to process actual jpg images.\n",
    "2. An introduction to convolutional networks (CNN).\n",
    "\n",
    "Once you learn the basics of these two threads, you will combine them to create a CNN that processes images. Let's get started.\n",
    "\n",
    "(This notebook is a remix of one by F. Chollet)\n",
    "\n",
    "## Part 1 Step 1: Downloading the data\n",
    "\n",
    "The cats vs. dogs dataset that we will use isn't packaged with Keras. It was made available by Kaggle.com as part of a computer vision \n",
    "competition in late 2013, back when convnets weren't quite mainstream. You can download the original dataset at: \n",
    "`https://www.kaggle.com/c/dogs-vs-cats/data` (you will need to create a Kaggle account if you don't already have one -- don't worry, the \n",
    "process is painless).\n",
    "\n",
    "The pictures are medium-resolution color JPEGs. They look like this:\n",
    "\n",
    "![cats_vs_dogs_samples](https://s3.amazonaws.com/book.keras.io/img/ch5/cats_vs_dogs_samples.jpg)\n",
    "\n",
    "Unsurprisingly, the cats vs. dogs Kaggle competition in 2013 was won by entrants who used convnets (Convoluational Neural Networks or CNNs). The best entries could achieve up to \n",
    "95% accuracy. In our own example, we will get fairly close to this accuracy even though we will be training our \n",
    "models on less than 10% of the data that was available to the competitors.\n",
    "This original dataset contains 25,000 images of dogs and cats (12,500 from each class) and is 543MB large (compressed). The zip file you will download contains a subset of this data. If you are interested in exploring more on your own you can download the full dataset from the Kaggle link above.\n",
    "\n",
    "After downloading and uncompressing the file, we will create a new dataset containing three subsets: a training set with 1000 samples of each class, a validation set with 500 samples of each class, and finally a test set with 500 samples of each class.\n",
    "\n",
    "Here are a few lines of code to do this:\n",
    "\n",
    "### First, download the zip file ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDJhyH6yzrNU",
    "outputId": "ab641f69-88fc-48cf-c28b-16016ba796da"
   },
   "outputs": [],
   "source": [
    "!wget http://zacharski.org/files/courses/cs419/cats_and_dogs.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb_z7GI9AqOO"
   },
   "source": [
    "### Unzip the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_BbTPF2zrfI",
    "outputId": "53089af1-fb63-48b3-c0ed-f2a1c2cb4971"
   },
   "outputs": [],
   "source": [
    "!unzip cats_and_dogs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urIZYPWI6fqI",
    "outputId": "eb136ab3-af59-4eb2-fdef-78050998ca98"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zCM0o0D8CRC5",
    "outputId": "9e05f1dc-b29f-40fa-9c12-5af0593a2781"
   },
   "outputs": [],
   "source": [
    "ls cats_and_dogs | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUJPv9NXAwrT"
   },
   "source": [
    "This creates a directory `cats_and_dogs` that contains 10,000 pictures of cats (files with the prefix `cat`) and dogs (with a prefix of `dog`)\n",
    "\n",
    "### Create the directory variables\n",
    "Currently we have all the files in one directory. We are going to move the files into a directory structure that looks like\n",
    "\n",
    "* train\n",
    "  * cat\n",
    "  * dog\n",
    "* validation \n",
    "  * cat\n",
    "  * dog\n",
    "* test\n",
    "  * cat\n",
    "  * dog\n",
    "\n",
    "\n",
    "Let's go ahead and instantiate variables with the correct paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfhwnGxElslG"
   },
   "outputs": [],
   "source": [
    "## Define the directories\n",
    "import os, shutil\n",
    "# The path to the directory where the original\n",
    "# dataset was uncompressed\n",
    "original_dataset_dir = 'cats_and_dogs'\n",
    "\n",
    "# The directory where we will\n",
    "# store our smaller dataset\n",
    "base_dir = 'cats_and_dogs_small'\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hq5ZgJF2CLSX"
   },
   "source": [
    "### Make and populate the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jXcmjDwzrpZ"
   },
   "outputs": [],
   "source": [
    "## NOW MAKE AND POPULATE THOSE DIRECTORIES\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(validation_dir)\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "os.mkdir(test_cats_dir)\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "# Copy first 1000 cat images to train_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Copy next 500 cat images to validation_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 cat images to test_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy first 1000 dog images to train_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to validation_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to test_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OPz69LG7Oxb"
   },
   "source": [
    "Take a look at the code block above to see the directories where the images are stored and to gain an understanding of the steps we took.\n",
    "\n",
    "\n",
    "## Part 1 Step 2: Data preprocessing\n",
    "\n",
    "As you already know by now, data should be formatted into appropriately pre-processed floating point tensors before being fed into our \n",
    "network. Currently, our data sits on a drive as JPEG files, so the steps for getting it into our network are roughly:\n",
    "\n",
    "* Read the picture files.\n",
    "* Decode the JPEG content to RBG grids of pixels.\n",
    "* Convert these into floating point tensors.\n",
    "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
    "\n",
    "It may seem a bit daunting, but thankfully Keras has utilities to take care of these steps automatically. Keras has a module with image \n",
    "processing helper tools, located at `keras.preprocessing.image`. In particular, it contains the class `ImageDataGenerator` which allows to \n",
    "quickly set up Python generators that can automatically turn image files on disk into batches of pre-processed tensors. This is what we \n",
    "will use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhNN2vCs7Ntz",
    "outputId": "3d37c7a0-1aa7-491f-e854-4e51851a5001"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjiR20Y48GH2"
   },
   "source": [
    "**note**: the generators convert the jpeg images to the `target_size`. In the example above, the images are scaled to 150x150x3.\n",
    "\n",
    "Suppose we construct a fully connected neural network model. We can fit our model to the data using the `train_generator` and `validation_generator` objects. The method `fit`, which we have used before, knows how to use data from data generators. One option with `fit` is to have the first argument be a Python generator that will yield batches of inputs and targets indefinitely, like ours does. \n",
    "\n",
    "Because the data is being generated endlessly, the generator needs to know  how many samples to draw from the generator before \n",
    "declaring an epoch over. This is the role of the `steps_per_epoch` argument: after having drawn `steps_per_epoch` batches from the \n",
    "generator, i.e. after having run for `steps_per_epoch` gradient descent steps, the fitting process will go to the next epoch. In our case, \n",
    "batches are 20-samples large, so it will take 100 batches until we see our target of 2000 samples. The math is super straight forward. For example, if our batch size is 25 how many batches to we need to accomdate 5,000 samples?  It's that simple.\n",
    "\n",
    "When using `fit`, one may pass a `validation_data` argument. Importantly, this argument is \n",
    "allowed to be a data generator itself, but it could be a tuple of Numpy arrays as well. If you pass a generator as `validation_data`, then \n",
    "this generator is expected to yield batches of validation data endlessly, and thus you should also specify the `validation_steps` argument, \n",
    "which tells the process how many batches to draw from the validation generator for evaluation.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "\n",
    "      history = model.fit(\n",
    "\t\t      train_generator,\n",
    "\t\t      steps_per_epoch=100,\n",
    "\t\t      epochs=30,\n",
    "\t\t      validation_data=validation_generator,\n",
    "\t\t      validation_steps=50)\n",
    "              \n",
    "You will be coming back to this example, so remember it is here!              \n",
    " \n",
    "## Part 1 Step 3: create and compile a fully connected model.\n",
    "We are going to construct a fully connected model like we did for the mnist data. The architecture should be:\n",
    "\n",
    "    ______________________________________________________________________\n",
    "    Layer (type)             Output Shape         Param #      Activation  \n",
    "    ======================================================================\n",
    "    flatten_1 (Flatten)      (None, 67500)        0         \n",
    "    ______________________________________________________________________\n",
    "    dense_3 (Dense)          (None, 512)          34560512     relu\n",
    "    ______________________________________________________________________\n",
    "    dense_4 (Dense)          (None, 1)            513          sigmoid\n",
    "    ======================================================================\n",
    "    Total params: 34,561,025\n",
    "    Trainable params: 34,561,025\n",
    "    Non-trainable params: 0\n",
    "    __________________________\n",
    "\n",
    "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
    "## <font color='#EE4C2C'>1. Create and compile the fully connected model</font> \n",
    "\n",
    "\n",
    "I will add the first layer, you write the other 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tb3HdMeT8SL1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Flatten(input_shape=(150, 150, 3)))\n",
    "\n",
    "## TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zuiKsSv8efM"
   },
   "source": [
    "## <font color='#EE4C2C'>2. Compile the network using the following parameters:</font> \n",
    " parameter | value\n",
    " :---: | :---:\n",
    " loss |'binary_crossentropy'\n",
    " optimizer| optimizers.RMSprop(lr=1e-4)\n",
    " metrics | ['accuracy']\n",
    "\n",
    " the optimizer parameter should look like \n",
    "\n",
    " ```\n",
    " optimizer=optimizers.RMSprop(lr=1e-4),\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcPYZtsR8dXE",
    "outputId": "9aef394b-d6dd-4c3c-8948-9b7030bc9533"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "\n",
    "## TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTaoXq1DC_06"
   },
   "source": [
    "(make sure the loss was 'binary_crossentropy')\n",
    "\n",
    "## <font color='#EE4C2C'>3. Fit the model</font> \n",
    "Remember when we said 'remember' up above? That should help you with the code to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6NsGYTGDSAP",
    "outputId": "a5f32d34-13dc-44bc-c842-b4a53131968f"
   },
   "outputs": [],
   "source": [
    "# TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUGYJcodWHFI"
   },
   "source": [
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/dogcat2.gif)\n",
    "\n",
    "(This picture from [Becoming Human](https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8))\n",
    "\n",
    "\n",
    "That took quite a while and the training accuracy was pretty poor. My last line looked like:\n",
    "\n",
    "```\n",
    "Epoch 30/30\n",
    "100/100 [==============================] - 9s 90ms/step - loss: 0.5624 - accuracy: 0.7045 - val_loss: 0.8046 - val_accuracy: 0.5560\n",
    "```\n",
    "So the accuracy on the training data was 70.45% and the accuracy on the validation data was only 55.6%. \n",
    "\n",
    "### Loss\n",
    "The loss was .5624 and .8046 on our training and test data respectively. The loss function compares the predictions of the network with the correct labels and describes how close those predictions are. The smaller the loss the better.\n",
    "We compiled our network using the binary crossentropy loss function:\n",
    "\n",
    "$$Loss= -{{1}\\over{N}}\\sum_{i=1}^Ny_i log(p(y_i))+(1-y_i)log(1-p(y_i))$$\n",
    "\n",
    "Consider the following small dataset with their true and predicted values:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dog | p(dog)\n",
    ":--- | :---\n",
    "1    | .8\n",
    "0    | .4\n",
    "\n",
    "So looking at the first row, the picture was of a dog and our model was 80% sure that it was a dog. Our loss would be...\n",
    "\n",
    "$$Loss= -{{1}\\over{2}}(1 (log(.8)) + 0(log(.2)) + 0(log(.4)) + 1(log(.6))$$\n",
    "\n",
    "$$= -{{1}\\over{2}}(1 (-0.223) + 0(-1.609) + 0(-0.916) + 1(-0.510)$$\n",
    "\n",
    "\n",
    "$$= -{{1}\\over{2}}(-0.223 + 0 + 0 + -0.510) = .366$$\n",
    "\n",
    "\n",
    "Now if you skipped over that formula, that is unfortunate. Take a few minutes, go back, look it over and you will see that there is no magic here. The loss computation is straightforward.\n",
    "\n",
    "### Accuracy on Test Data\n",
    "Let's see how accurate our model is on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FaooXZymWGug",
    "outputId": "a7c85083-88e9-4838-9277-6f20271aff30"
   },
   "outputs": [],
   "source": [
    "scoreSeg = network.evaluate(test_generator)\n",
    "print(\"Accuracy: \", scoreSeg[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gM1cSZuW0if"
   },
   "source": [
    "That is a disappointing result. Let's pause our work on this dataset to look at a new network architecture.\n",
    "\n",
    "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
    "# <font color='#EE4C2C'>Part 2. Convolutional Neural Networks</font> \n",
    "\n",
    "\n",
    "## A guided tour\n",
    "\n",
    "Let's start with what we learned in the first Keras Python Notebook\n",
    "\n",
    "## Part 2 Step 1. Load the MNIST Dataset\n",
    "First let's load the MNIST dataset from Keras into Numpy arrays called: \n",
    "\n",
    "     train_images, train_labels, test_images, test_labels\n",
    "     \n",
    "(We've done this before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AleyFndHZaAX",
    "outputId": "b3f3a2f0-2f83-4b2c-cc4f-af1c47c69d1d"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "## TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HDgNLkIZkoI"
   },
   "source": [
    "## Part 2 Step 2: Reshape the Data\n",
    "In the first notebook we reshaped the data into\n",
    "\n",
    "     (60000, 28 * 28)\n",
    "     \n",
    "Basically, we flattened the image. For this notebook let's retain the 2D structure and reshape it:\n",
    "\n",
    "     ((60000, 28, 28, 1))\n",
    "     \n",
    "At the same time we should also set the type to be `float32` in the range [0,1]\n",
    "\n",
    "At the end of this step you should have new values for `train_images` and `test_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGx3sp-jZvRy",
    "outputId": "39c47f62-07d3-455e-f37d-6f071133968b"
   },
   "outputs": [],
   "source": [
    "train_images = \"TO DO\"\n",
    "test_images = \"TO DO\"\n",
    "\n",
    "# TO DO\n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1qscTKkZ67_"
   },
   "source": [
    "## Part 2 Step 3: Categorically Encode the Labels\n",
    "\n",
    "You should know how to do this from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zf_4139HaDr_"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWgy7cPharRu"
   },
   "source": [
    "## Part 2 Step 4: Creating the Model - The ConvNet layers\n",
    "This part I will give to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c60Mlk0xa2BG",
    "outputId": "de93fdca-68af-4672-b669-f339efa45ad0"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOznjLwcbtXU"
   },
   "source": [
    "## Part 2 Step 5. Adding Layers\n",
    "Now we need to flatten the outputs of the ConvNet layers to the 1D representation our classifier needs.\n",
    "The classification layer will be exactly the same as that in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uarwxdh4cglb"
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "\n",
    "# TO DO\n",
    "# ADD A 64 NODE DENSE LAYER WITH ACTIVATION RELU\n",
    "\n",
    "# ADD CLASSIFICATION LAYER ACTIVATION SOFTMAX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ-S0bqrctjp"
   },
   "source": [
    "## Part 2 Step 6: Compile the Model\n",
    "Now it is time to compile the model. Use the same optimizer, loss function, and accuracy metrics we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSRk0I8GgdbF",
    "outputId": "ab351669-5c98-4222-f3cd-90a7958be209"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpdG_C7Ng2w1"
   },
   "source": [
    "Now it is time to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIDH1sO2g5lj",
    "outputId": "824907ac-9ee6-4b4f-a9d3-ac7b37fc5f4d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGspk72GlRA6"
   },
   "source": [
    "## Part 2 Step 8. Run the Model on The Test Data\n",
    "Run the Model on the Test Data and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yt4-C5ltlY3q",
    "outputId": "ef6788b5-78aa-4210-a467-1fc8640a5bc6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U38cIE3nkXZ"
   },
   "source": [
    "When you compare the performance this CNN model has over the model from our previous notebook you will see that it halved the error rate. This is extremely impressive!\n",
    "\n",
    "## Part 2 Step 9. Graph The Loss and Accuracy\n",
    "Let's use Matplotlib to plot the training and validation loss side by side, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "WVg_L9shn4U0",
    "outputId": "df6ac19c-adaa-4642-d162-e59f1793fe3d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnoAgXcFyx5-"
   },
   "source": [
    "Notice that the accuracy lines for training and validation closely match each other. The same is true for the loss lines. This indicates that our model is not overfitting.\n",
    "\n",
    "# Part 3: Dogs 'n Cats with ConvNets\n",
    "This Python notebook is a slight remix of one by François Chollet for his book *Deep Learning With Python*\n",
    "\n",
    "## Previously in part 1... \n",
    "we downloaded the data then divided it up into a set of image files inside a number of directories. Let's make sure we have those images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHqWKx4gyx5_",
    "outputId": "7b9f3978-4290-475b-e641-2be0ca194cd0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = 'cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "\n",
    "\n",
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsG4Vd0Byx6C"
   },
   "source": [
    "This should print:\n",
    "    \n",
    "    total training cat images: 1000\n",
    "    total training dog images: 1000\n",
    "    total validation cat images: 500\n",
    "    total validation dog images: 500\n",
    "    total test cat images: 500\n",
    "    total test dog images: 500\n",
    "\n",
    "![](https://raw.githubusercontent.com/zacharski/datamining-guide/master/labs/pics/PyDivideTwo.png)\n",
    "## <font color='#EE4C2C'>Part 3 Step 1: Building a ConvNet Model</font> \n",
    "\n",
    "![](https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/dogcatCNN.png)\n",
    "We've already built a small convnet for MNIST in the previous example, so you should be familiar with them. We will reuse the same general structure: our convnet will be a stack of alternated `Conv2D` (with relu activation) and `MaxPooling2D` layers. Here are the steps we would like to do:\n",
    "\n",
    "1. Create a sequential model\n",
    "2. Add a `Conv2D` layer. Use 3x3 patches and a depth of 32. The input with be 150 x 150 pixel RGB images (depth of 3)\n",
    "3. Add a `MaxPooling2D`  with a patch size of 2 x 2. \n",
    "4. Add another `Conv2D` layer. Use 3x3 patches and a depth of 64. \n",
    "5. Add a `MaxPooling2D`  with a patch size of 2 x 2. \n",
    "6. Add another `Conv2D` layer. Use 3x3 patches and a depth of 128.\n",
    "7. Add a `MaxPooling2D`  with a patch size of 2 x 2. \n",
    "8. Add another `Conv2D` layer. Use 3x3 patches and a depth of 128.\n",
    "9. Add a `MaxPooling2D`  with a patch size of 2 x 2. \n",
    "10. Finish up by flattening ...\n",
    "11. Add a dense layer of 512\n",
    "12. Add a binary classification layer with activation sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK_yJZu4yx6C"
   },
   "outputs": [],
   "source": [
    "# TO DO\n",
    "\n",
    "# ADD YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFWCVpe6yx6F"
   },
   "source": [
    "### Verify that we did it right. \n",
    "Let's check by using the summary method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlNZ7Zmtyx6F",
    "outputId": "6682b1bd-e03f-49c1-873f-4869b80576d8"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzxuSDUJyx6H"
   },
   "source": [
    "You should see:\n",
    "    \n",
    "    \n",
    "\t\t_________________________________________________________________\n",
    "\t\tLayer (type)                 Output Shape              Param #   \n",
    "\t\t=================================================================\n",
    "\t\tconv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
    "\t\t_________________________________________________________________\n",
    "\t\tmax_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tconv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
    "\t\t_________________________________________________________________\n",
    "\t\tmax_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tconv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
    "\t\t_________________________________________________________________\n",
    "\t\tmax_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tconv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
    "\t\t_________________________________________________________________\n",
    "\t\tmax_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tflatten_1 (Flatten)          (None, 6272)              0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tdense_1 (Dense)              (None, 512)               3211776   \n",
    "\t\t_________________________________________________________________\n",
    "\t\tdense_2 (Dense)              (None, 1)                 513       \n",
    "\t\t=================================================================\n",
    "\t\tTotal params: 3,453,121\n",
    "\t\tTrainable params: 3,453,121\n",
    "\t\tNon-trainable params: 0\n",
    "\n",
    "\t\t\n",
    "## <font color='#EE4C2C'>Part 3 Step 2: Compile the Model</font> \n",
    "\t\t    \n",
    "\n",
    "Set the parameters:\n",
    "\n",
    "* set loss to be binary_crossentropy\n",
    "* use `optimizers.RMSprop(lr=1e-4)` as the optimizer\n",
    "* for metrics use `acc`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ji6e-bJzyx6I",
    "outputId": "0e370b4e-b83c-4351-f442-97caabee8e65"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUr2Ekdyyx6M"
   },
   "source": [
    "\n",
    "## <font color='#EE4C2C'>Part 3 Step 3: Data Preprocessing</font> \n",
    "\n",
    "Use the same data preprocessing steps we used for the original Dogs n' Cats. You should create a `train_generator`, a `test_generator` and a `validation_generator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_HxrT6zyx6M",
    "outputId": "c4deb55e-70c6-45f7-f799-6a6c584ddf4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOgRTCkPyx6P"
   },
   "source": [
    "## <font color='#EE4C2C'>Part 3 Step 4: Fit the Model</font> \n",
    "l\n",
    "Use `fit_generator`. Don't forget to save the history.\n",
    "\n",
    "1. Use 30 epochs\n",
    "2. Each with 100 steps\n",
    "3. Use the `validation_generator` as the validation data\n",
    "4. Set the validation steps to 50.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8OU6GU2yx6P",
    "outputId": "0f4e2850-6689-4b0c-9bce-380efb9b76bf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NbFrXPfyx6R"
   },
   "source": [
    "That is a total amazing accuracy on the training data and so-so accuracy on the validation set. \n",
    "\n",
    "## <font color='#EE4C2C'>Part 3 Step 5: Evaluate the model using the test data</font> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULZoKdM_qQne",
    "outputId": "74014a05-85ed-4a17-aac8-f8672a0218ba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1u0G5Livyx6S",
    "outputId": "e0547412-c593-469f-a56b-d95e75b33d5e"
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuyvhGJAyx6U"
   },
   "source": [
    " ## <font color='#EE4C2C'>Part 3 Step 6: Plot the Loss and Accuracy</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "GgYlpVrcyx6V",
    "outputId": "657ecb82-52a4-4b75-c1d3-038a6b79849c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcLVYJDAyx6X"
   },
   "source": [
    "## Look at those plots. \n",
    "What do they indicate? Seriously, spend a few minutes looking at them. Please.\n",
    "\n",
    "These plots show a classic case of overfitting. If you look at the blue dot line in the accuracy plot, which represents the accuracy on the training data, it increases in a beautiful linear way over the course of the epochs until it reaches near 100% accuracy (98.5% in my case). In contrast, the accuracy on the validation data sort of stalls out around epoch 5 and doesn't really improve. The same is true looking at the loss chart. The loss on the training data is a nice linear slope down until it approaches 0. But the validation loss actually goes up! \n",
    "\n",
    "One cause of overfitting is too small a dataset. In our case we only used 2,000 images. With such a small dataset overfitting is a major concern. One way of combatting overfitting is to use data augmentation.\n",
    "\n",
    "\n",
    "# Using data augmentation\n",
    "\n",
    "This section is directly from François Chollet \n",
    "\n",
    "Overfitting is caused by having too few samples to learn from, rendering us unable to train a model able to generalize to new data. Given infinite data, our model would be exposed to every possible aspect of the data distribution at hand: we would never overfit. Data augmentation takes the approach of generating more training data from existing training samples, by \"augmenting\" the samples via a number of random transformations that yield believable-looking images. The goal is that at training time, our model would never see the exact same picture twice. This helps the model get exposed to more aspects of the data and generalize better.\n",
    "In Keras, this can be done by configuring a number of random transformations to be performed on the images read by our ImageDataGenerator instance. Let's get started with an example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZjndskCyx6X"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmnjsJseyx6Z"
   },
   "source": [
    "These are just a few of the options available (for more, see the Keras documentation). Let's quickly go over what we just wrote:\n",
    "\n",
    "* `rotation_range` is a value in degrees (0-180), a range within which to randomly rotate pictures.\n",
    "* `width_shift` and `height_shift` are ranges (as a fraction of total width or height) within which to randomly translate pictures \n",
    "vertically or horizontally.\n",
    "* `shear_range` is for randomly applying shearing transformations.\n",
    "* `zoom_range` is for randomly zooming inside pictures.\n",
    "* `horizontal_flip` is for randomly flipping half of the images horizontally -- relevant when there are no assumptions of horizontal \n",
    "asymmetry (e.g. real-world pictures).\n",
    "* `fill_mode` is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
    "\n",
    "Let's take a look at our augmented images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SyctSabNyx6a",
    "outputId": "1f1ee61a-33c9-4fa4-f210-77d78db25fbf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# This is module with image preprocessing utilities\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "\n",
    "fnames = [os.path.join(train_dogs_dir, fname) for fname in os.listdir(train_dogs_dir)]\n",
    "\n",
    "# We pick one image to \"augment\"\n",
    "#print(os.listdir(train_dogs_dir).index('dog.788.jpg'))\n",
    "img_path = fnames[107]\n",
    "# Read the image and resize it\n",
    "img = load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "# Convert it to a Numpy array with shape (150, 150, 3)\n",
    "x = img_to_array(img)\n",
    "\n",
    "# Reshape it to (1, 150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images.\n",
    "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktJzowH-yx6c"
   },
   "source": [
    "If we train a new network using this data augmentation configuration, our network will never see twice the same input. However, the inputs \n",
    "that it sees are still heavily intercorrelated, since they come from a small number of original images -- we cannot produce new information, \n",
    "we can only remix existing information. As such, this might not be quite enough to completely get rid of overfitting. To further fight \n",
    "overfitting, we will also add a Dropout layer to our model using: \n",
    "\n",
    "     aug_model.add(layers.Dropout(0.5))\n",
    "\n",
    "between the flatten layer and the densely-connected classifier. Copy your model declaration from above and add this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edQNp7Bmyx6c"
   },
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "aug_model = models.Sequential()\n",
    "\n",
    "## TO DO\n",
    "aug_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNGadQpByx6f"
   },
   "source": [
    "## Compile the Model\n",
    "Use the same settings as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0ZBcKxSyx6f"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# TO DO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkJ6wApvyx6i"
   },
   "source": [
    "Sweet! Here is the code for the augmented data generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "qh7tX8x9yx6i",
    "outputId": "9c8a54fd-7dc8-4a48-e88c-9130bccf6517"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "do9wvmBKyx6l"
   },
   "source": [
    "## Fit the model\n",
    "Now we will use these new generators to fit the model.\n",
    "\n",
    "Use `fit_generator`. Don't forget to save the history.\n",
    "\n",
    "1. Use 100 epochs\n",
    "2. Each with 100 steps\n",
    "3. Use the `validation_generator` as the validation data\n",
    "4. Set the validation steps to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "p1kgvh-jyx6l",
    "outputId": "c8af7bdb-d15a-4649-e192-1313202c8cde"
   },
   "outputs": [],
   "source": [
    "history = \"TO DO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "zuLVxf_pvBRX",
    "outputId": "e4a73756-55e0-4bbd-bc7a-2d4db8cab484"
   },
   "outputs": [],
   "source": [
    "scoreSeg = aug_model.evaluate(test_generator)\n",
    "print(\"Accuracy: \", scoreSeg[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgjZ7dwMyx6n"
   },
   "source": [
    "### Let's plot our results again\n",
    "One plot showing the training and validation accuracy, another showing training and validation loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "d3qZxTBtyx6o",
    "outputId": "aa33b8ce-e1d1-4aec-8894-f23a9592d666"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "oss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA-J_bjeyx6q"
   },
   "source": [
    "Because of image augmentation and dropout we are no longer overfitting-- the lines for the training and validation accuracy are pretty well lined up as are the lines for loss. With this we get about a 15% improvement over our previous model.\n",
    "\n",
    "With other techniques we can probably improve our model to reach a bit higher accuracies but we will hit a limit because of the paucity of data.In the next notebook we will examine ways of using pre-trained models to improve our accuracy.\n",
    "\n",
    "\n",
    "## Just for fun\n",
    "Just for grins, let's see how well our model does on a few test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2aEG-i_uyx6q",
    "outputId": "d17d6b56-d832-426c-ba63-d100bfdcf38e"
   },
   "outputs": [],
   "source": [
    "!ls cats_and_dogs_small/test/cats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVqA9mJw-BnV"
   },
   "outputs": [],
   "source": [
    "img_path = test_dogs_dir + '/dog.1999.jpg'\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img = image.load_img(img_path, target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "anBDPXhv-rID",
    "outputId": "887f4b96-799f-4971-d474-0cb5309cb4e2"
   },
   "outputs": [],
   "source": [
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XNcnfzBT_o2W",
    "outputId": "7af76fa2-0a3f-4bfe-a7f9-bd199fde3511"
   },
   "outputs": [],
   "source": [
    "model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38N1shBeWmA5"
   },
   "source": [
    "Our model is 99% certain this is a dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogvH399fAGNs"
   },
   "outputs": [],
   "source": [
    "img_path = test_cats_dir + '/cat.1999.jpg'\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img = image.load_img(img_path, target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "NMDfvFFKAkI9",
    "outputId": "3bcbc55c-bd8b-4941-bc11-db6b0d3f88c2"
   },
   "outputs": [],
   "source": [
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UKyzSncHAmU1",
    "outputId": "f34c6711-16ed-4045-dc85-f6a45bac33bc"
   },
   "outputs": [],
   "source": [
    "model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMM495qCW433"
   },
   "source": [
    "Our model is 0.3% certain that this is a dog (meaning it is 99.7% sure it is not a dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "ykCGJSoABEOn",
    "outputId": "110addff-386f-4f41-e751-82f65a9e858b"
   },
   "outputs": [],
   "source": [
    "img_path = test_dogs_dir + '/dog.1800.jpg'\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "lm_YxDhdB22D",
    "outputId": "f163acbc-b128-49d2-a689-bee2ac7a18e4"
   },
   "outputs": [],
   "source": [
    "model.predict(img_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ai3knmFsMvB5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "_HDgNLkIZkoI",
    "i1qscTKkZ67_",
    "SWgy7cPharRu",
    "JOznjLwcbtXU",
    "pQ-S0bqrctjp",
    "DGspk72GlRA6",
    "6U38cIE3nkXZ",
    "WFWCVpe6yx6F",
    "CzxuSDUJyx6H",
    "UUr2Ekdyyx6M",
    "jOgRTCkPyx6P",
    "0NbFrXPfyx6R",
    "XuyvhGJAyx6U",
    "dNGadQpByx6f",
    "do9wvmBKyx6l",
    "BgjZ7dwMyx6n"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
